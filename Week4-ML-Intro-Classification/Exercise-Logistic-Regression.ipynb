{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our first machine learning model: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our libraries "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import and inspect the Titanic dataset.\n",
    "* Load the titanic data set into a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the titanic data set into a pandas dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data dictionary\n",
    "<img src='https://miro.medium.com/max/1260/1*rr3UGlpEv_PSMc1pyqa4Uw.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify which columns have null values. \n",
    "Inspect which varibles may be good / not good for using as features based on null values. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify which columns have null values. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check to see if our data has any duplicate rows.\n",
    "If so, remove the duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check to see if our data has any duplicate rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use sns.pariplot to visualize.\n",
    "* Set the hue='survived'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use sns.pariplot to visualize."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "For your first model, only include use the `fare` and `sex` as features.\n",
    "* Convert the `sex` feature to a continuous value by using `pd.get_dummies()`.\n",
    "* Drop the `sex_female` column as it is the identical inverse of `sex_male`. \n",
    "    * Hint, you can use `drop_first=True` in the `pd.get_dummies()` function to have this done automatically.\n",
    "* Create a `selected_features` variable that is a list of `fare` and `sex_male`.  \n",
    "* Define your X and y variables.\n",
    "    * `X` is your selected features\n",
    "    * `y` is your target features (survived). \n",
    "* Split your data into training and testing groups by using `train_test_split()`\n",
    "    * __IMPORTANT: In `train_test_split` set `random_state=45`, so when you make another model, you can run it on the same random split of data.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the sex column into a continuous variable by using pd.get_dummies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select our features \n",
    "   * only include use the `fare` and `sex_male` as features for this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select our features\n",
    "selected_features = []\n",
    "\n",
    "# Set X to be the features we are going to use.\n",
    "X = ???\n",
    "\n",
    "# Set y to be our target variable. \n",
    "y = ???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split our data into the testing and training groups. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our data into testing and training.\n",
    "X_train, X_test, y_train, y_test = ???\n",
    "\n",
    "# Print the length and width of our testing data.\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build and train your model\n",
    "* Initialize an empty Logistic Regression model. \n",
    "* Fit your model with your training data. \n",
    "* Predict the values of your testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initalize our model\n",
    "\n",
    "\n",
    "# Train our model using our training data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate your model\n",
    "1. Make predictions of your test data and save them as `y_pred`. \n",
    "1. Calculate and print the accuracy, precision, recall, and f1 scores of your model.\n",
    "    * Hint, sklearn provides helper functions for this.\n",
    "1. Plot the confusion matrix of your predicted results. \n",
    "    * How many True Positives and True Negatives did your model get?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Make predictions of your test data and save them as `y_pred`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Calculate and print the accuracy, precision, recall, and f1 scores of your model.\n",
    "\n",
    "# Calculate our accuracy\n",
    "accuracy = ???\n",
    "\n",
    "# Calculate our precision score\n",
    "precision = ???\n",
    "\n",
    "# Calculate our recall score\n",
    "recall = ???\n",
    "\n",
    "f1 = ???\n",
    "\n",
    "# Print each of our scores to inspect performance.\n",
    "print(\"Accuracy Score: %f\" % accuracy)\n",
    "print(\"Precision Score: %f\" % precision)\n",
    "print(\"Recall Score: %f\" % recall)\n",
    "print('F1 Score %f' % f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Plot a confusion matrix of your predicted results. \n",
    "import matplotlib.pyplot as plt \n",
    "fig = plt.figure(figsize=(8,8))\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual');\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many True Positives and True Negatives did your model get?\n",
    "print('??? True Negatives and ??? True Positives')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create another model, call this `model_2`.  This time also include the p_class and embarked features. \n",
    "1. Run `pd.get_dummies()` on pclass and embarked of your DataFrame.\n",
    "1. Update your `selected_features` to include the new pclass, embarked, sibsp, and parch features.\n",
    "1. Define your `X` and `y` variables.\n",
    "1. Break your data into training and testing groups.\n",
    "    * __IMPORTANT, In `train_test_split` set `random_state=45` so we will be using the same data rows as our first model__.\n",
    "1. Initialize a new model, call this one `model_2`\n",
    "1. Fit / Train your new model\n",
    "1. Make predictions of your test data and save them as `y_pred`. \n",
    "1. Calculate and print the accuracy, precision, recall, and f1 scores of your model.\n",
    "1. Plot the confusion matrix of your predicted results. \n",
    "    * How many True Positives and True Negatives did your model get?\n",
    "    \n",
    "Compare the results to your first model. Which model had a better accuracy, recall, precision, and f1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/titanic.csv')\n",
    "\n",
    "# Run pd.get_dummies on pclass and embarked of your DataFrame.\n",
    "\n",
    "\n",
    "# Update your `selected_features` to include the new pclass and embarked features. \n",
    "\n",
    "# Define your X and y variables\n",
    "\n",
    "\n",
    "# Split our data into testing and training.\n",
    "# !!! Remeber to use the same random state as you used before\n",
    "\n",
    "\n",
    "# Initalize our model_2\n",
    "model_2 = LogisticRegression()\n",
    "\n",
    "# Fit / Train our model using our training data.\n",
    "\n",
    "# Make new predicitions using our testing data. \n",
    "\n",
    "# Calculate our accuracy\n",
    "accuracy_2 = ???\n",
    "\n",
    "# Calculate our precision score\n",
    "precision_2 = ???\n",
    "\n",
    "# Calculate our recall score\n",
    "recall_2 = ???\n",
    "\n",
    "# Calculate your f1-score\n",
    "f1_2 = ???\n",
    "\n",
    "# Print each of our scores to inspect performance.\n",
    "print(\"Accuracy Score: %f\" % accuracy_2)\n",
    "print(\"Precision Score: %f\" % precision_2)\n",
    "print(\"Recall Score: %f\" % recall_2)\n",
    "print('F1 Score %f' % f1_2)\n",
    "\n",
    "# Plot your confusion matrix.\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual');\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXTRA CREDIT\n",
    "* Use age as a feature. \n",
    "* How will you fill the null values?\n",
    "    * Hint, use `df.age.fillna(???)`\n",
    "* Make a new feature that 'traveled_alone'.  The sibsp and parch contain the amout of people they are traveling with. Mark everyone that has no sibsp or parch as traveled alone set to 1 and everyone else set to 0. \n",
    "    * Once you have this traveled_alone column, you dont need to use the the sibsp and parch cols in your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/titanic.csv')\n",
    "\n",
    "# Run pd.get_dummies on sex, pclass, and embarked of your DataFrame.\n",
    "\n",
    "\n",
    "# Fill null age values with mean age.\n",
    "\n",
    "\n",
    "# Create new traveled_alone feature\n",
    "\n",
    "\n",
    "# Update your `selected_features` to include the new traveled alone and age\n",
    "\n",
    "\n",
    "# Define your X and y variables\n",
    "\n",
    "\n",
    "# Split our data into testing and training.\n",
    "# Remeber to use the same random state as you used before\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=45)\n",
    "\n",
    "\n",
    "# Initalize our model\n",
    "model_3 = LogisticRegression()\n",
    "\n",
    "# Fit / Train our model using our training data.\n",
    "\n",
    "# Make new predicitions using our testing data. \n",
    "\n",
    "\n",
    "# Calculate our accuracy\n",
    "accuracy_3 = \n",
    "\n",
    "# Calculate our precision score\n",
    "precision_3 = \n",
    "\n",
    "# Calculate our recall score\n",
    "recall_3 = \n",
    "\n",
    "# Calculate your f1-score\n",
    "f1_3 = \n",
    "\n",
    "# Print each of our scores to inspect performance.\n",
    "print(\"Accuracy Score: %f\" % accuracy_3)\n",
    "print(\"Precision Score: %f\" % precision_3)\n",
    "print(\"Recall Score: %f\" % recall_3)\n",
    "print('F1 Score %f' % f1_3)\n",
    "\n",
    "# Plot your confusion matrix.\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
